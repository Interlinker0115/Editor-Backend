# Efecto del número de réplicas y número de tratamientos con distribución no normal en la potencia de pruebas de normalidad 

Manrique Camacho Pochet ${ }^{1}$, Amanda Cedeño Guzmán², Iván Daniel Rodríguez Cruz ${ }^{3}$ y<br>Marie Sofia Villalobos Martínez ${ }^{4}$<br>manrique.camacho@ucr.ac.cr, amanda.cedeno@ucr.ac.cr, $\underline{\text { ivan.rodriguezcruz@ucr.ac.cr y }}$<br>marie.villalobos@ucr.ac.cr

## RESUMEN

En el contexto de la regresión lineal y los modelos experimentales, uno de los supuestos fundamentales radica en que los residuos se distribuyan de forma normal. De esta forma, se llevó a cabo una simulación con el propósito de analizar el impacto de las distribuciones asimétricas positivas en los valores residuales de un modelo experimental. Por consiguiente, se evaluó la potencia de las pruebas de bondad de ajuste para verificar el supuesto de normalidad de los residuos. Al realizar el presente análisis se emplearon tanto pruebas paramétricas como no paramétricas (Shapiro-Wilks, Jarque-Bera y Kolmogorov-Smirnov-Lilliefors, respectivamente) con distinta cantidad de réplicas y haciendo uso de diversos números de distribuciones asimétricas exponenciales con un determinado parámetro $\beta$ y mediante diez mil iteraciones. Los resultados muestran que de forma íntegra la prueba de Shapiro-Wilks en los múltiples escenarios obtuvo una potencia superior a las demás. En cuanto a los tamaños muestrales, se encontró que, a mayor tamaño de muestra, mayor potencia; de la misma forma, entre más cantidad de tratamientos con distribución exponencial, se obtiene una potencia de la prueba más alta. Además, la prueba no paramétrica de Kolmogorov-Smirnov con corrección de Lilliefors es la que denotó un menor rendimiento en comparación con las otras dos pruebas a través del estudio.

PALABRAS CLAVE: Simulación, valores residuales, distribución exponencial, pruebas de bondad de ajuste.

## INTRODUCCIÓN

Al momento de ajustar un modelo lineal uno de los inconvenientes que generalmente se presenta es la falta de normalidad de los residuos, es decir, ocurre un incumplimiento del supuesto de normalidad. Dicha suposición es considerada por muchos críticos en el área como una de las premisas más relevantes debido a su importancia al interpretar y hacer inferencias válidas (estimación puntual, intervalos de confianza, etc.) sobre los datos que se analizan (Thadewald y Büning, 2007).

[^0]Por consiguiente, las pruebas de bondad de ajuste han sido una herramienta primordial, junto al análisis gráfico, por ejemplo, los gráficos de $Q-Q$ plot o los histogramas (véase la Figura 1), que funcionan para poder contrastar la hipótesis nula de que la distribución de los residuos de los datos proviene de una distribución normal (esta hipótesis está contenida en la expresión (2)).

## Figura 1

Ejemplo de un gráfico Q-Q para analizar el cumplimiento del supuesto de normalidad de forma visual.

![](https://cdn.mathpix.com/cropped/2024_09_30_a62b0a14488a0b1bcc33g-02.jpg?height=725&width=1047&top_left_y=624&top_left_x=517)

En consecuencia, una práctica común para verificar el cumplimiento de este supuesto es efectuar estudios de simulación con el fin de analizar cómo afecta, p. ej., el comportamiento de distintas distribuciones asimétricas positivas (como la distribución Exponencial, Gamma, Weibull, entre otras) al cálculo de la potencia de la prueba (Nosakhare y Bright, 2017). Para contrastar las hipótesis se llevarán a cabo diferentes pruebas de normalidad. Asimismo, se pueden encontrar estudios de simulación que se centran en probar si determinantes como los valores extremos (Coin, 2008; Ventura-León et al., 2022), la falta de homocedasticidad (Mak, 2000), la comparación de pruebas de bondad ajuste (paramétricas y no paramétricas) (Thadewald y Büning, 2007) o el tamaño de la muestra (Dufour et al., 1998) tienen influencia al tomar la decisión de rechazar o no la hipótesis del supuesto de normalidad de los residuos previamente mencionado.

De esta forma, para poder analizar el cumplimiento del supuesto de normalidad existen una diversidad de prueba que desde distintos marcos metodológicos (paramétricos y no paramétricos) logran, en menor o mayor medida, una respuesta para precisar si los residuos de un determinado conjunto de datos se distribuyen o no de forma normal. Entre las pruebas de bondad de ajuste más comunes se encuentran las pruebas Shapiro-Wilks (SW) (Shapiro y Wilk, 1965), la prueba de Kolmogorov-Smirnov con la corrección Lilliefors $\left(K S_{L}\right)$ (Gross y Ligges, 2015) y la prueba robusta de Jarque-Bera (JB) (Jarque y Bera, 1980), entre muchas otras más.

Sin embargo, es importante tener en cuenta que cada una de estas pruebas mencionadas varía en términos de las características que utilizan para analizar los conjuntos de datos. Las diferencias entre estas pruebas de bondad de ajuste mencionadas anteriormente incluyen el uso de
la asimetría y la curtosis, la función de distribución y la relación lineal entre la variable y la variable normal estándar. Esta diversidad permite evaluar diferentes aspectos de la distribución sin que los enfoques sean demasiado similares entre sí (Mohd Razali y Yap, 2011, pp. 21-22). No obstante, este aspecto se describirá de manera más precisa en la sección metodológica del presente escrito.

En suma, este estudio hará hincapié en analizar el impacto de las distribuciones asimétricas positivas en los valores residuales de un modelo experimental, el cual contará con dos factores y un efecto de interacción entre ellos al evaluar la potencia de las pruebas de bondad de ajuste para verificar el supuesto de normalidad de los residuos. En concreto, se indagará cómo la distribución exponencial con parámetro $\beta$ en cada tratamiento afecta la capacidad de la prueba para detectar la falta de normalidad en los residuos.

## METODOLOGÍA

Para poder llevar a cabo el estudio de simulación vinculado al tema propuesto, es necesario establecer previamente una serie de conceptos básicos relacionados con los estadísticos utilizados en las pruebas de bondad de ajuste que fueron empleadas, así como otros términos relevantes para el objetivo de este trabajo. En la sección de Simulación se explicará más al por menor cómo se creó y se trabajó la simulación propuesta.

## Supuesto de normalidad

En diseños experimentales un modelo lineal se puede expresar tal que

$$
y_{i j}=\mu+\tau_{i}+\varepsilon_{i j}
$$

Donde $\varepsilon_{i j} \sim N\left(0, \sigma^{2}\right)$ y $Y_{i j} \sim N\left(\mu, \sigma^{2}\right)$. Es decir, la distribución condicional de la variable respuesta bajo cada tratamiento sigue una distribución normal, y todas las distribuciones condicionales de la respuesta bajo los tratamientos cuentan con la misma varianza. Cabe denotar que este supuesto se asocia teóricamente al Teorema del Límite Central.

Al tener en cuenta que $\varepsilon_{i j}$ y $Y_{i j}$ deben distribuirse normalmente, entonces el supuesto de normalidad de los residuos es fundamental debido a que cualquier función lineal de variables distribuidas normalmente también seguirá una distribución normal (Gujarati y Porter, 2010, p. 99). Igualmente, al suponer normalidad los estimadores de Mínimos Cuadrados Ordinarios o MCO se van a comportar como EIVM (Estimador Insesgado de Varianza Mínima) y son consistentes (cuando $n \rightarrow$ $\infty$ los estimadores cada vez se acercan más al valor verdadero del parámetro).

## Figura 2

Densidad (izquierda) y gráfico $Q-Q$ (derecha) de los residuos de un modelo lineal, estos datos se distribuyen aproximadamente normal.

![](https://cdn.mathpix.com/cropped/2024_09_30_a62b0a14488a0b1bcc33g-04.jpg?height=727&width=1288&top_left_y=444&top_left_x=402)

Nota. Elaboración propia con datos de la base quakes presente en el paquete datasets (versión 3.6.2) en $\mathrm{R}(4.3 .1)$.

Sin embargo, suponer normalidad de los residuos muchas veces es muy complicado debido a la naturaleza de los datos, en resultado existen ciertas pruebas de bondad de ajuste que analizan el supuesto asociado a que los residuos se distribuyen normalmente. Además, para (Dufour et al., 1998) dicho supuesto supone una seguridad estadística al momento de inferir y generar intervalos de confianza para responder a los objetivos de investigación.

## Hipótesis de normalidad

Al momento de evaluar el cumplimiento de un test que analice el supuesto de normalidad se debe tener en cuenta que se está contrastando la siguiente hipótesis:
$H_{0}:$ Los residuos se distribuyen normal.
$H_{1}$ : Los residuos no se distribuyen normal.

Con este contraste, las pruebas de bondad de ajuste que se describirán en el siguiente apartado se centran para poder determinar un estadístico y una probabilidad asociada a él, la cual hará válida o no esta hipótesis referente a la distribución de los datos.

## Pruebas de bondad de ajuste

## Shapiro-Wilks

El test de normalidad de Shapiro-Wilks se emplea para evaluar la hipótesis de si una muestra específica $n$ proviene de una distribución normal (Shapiro y Wilk, 1965). El estadístico asociado W está expresado por la siguiente fórmula:

$$
W=\frac{b^{2}}{S^{2}}=\frac{\left(\sum_{i=1}^{n / 2} a_{i} x_{i}^{*}\right)^{2}}{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}
$$

Donde $a_{i}$ es una serie de pesos establecidos en el trabajo original de Shapiro-Willks. Los pesos se calcularon a partir de los cuantilos de una distribución teórica estadística. Además, el denominador del estadístico $W$ corresponde a la fórmula que toma la varianza, y los $x_{i}^{*}$, según los autores originales, deben estar ordenado de forma descendente.

Igualmente, este test es más sensible a tamaños de muestra más grandes y por ende posee más potencia (Shapiro y Wilk, 1965). No obstante, se ha probado que para tamaños de muestra de $n<20$ el estadístico $W$ también se comporta de buena forma (Shapiro y Wilk, 1965, p. 602). Este último hecho, fue mejorado por Royston (1995) que bajo ciertas modificaciones en las tablas de los pesos que asignaron los autores principales desde un inicio, se logró potenciar el uso de este estadístico $W$ para muestras que estén en un rango de $3 \leq n \leq 5000$, aproximadamente (Mohd Razali y Yap, 2011, p. 25). En $R$ la función asociada a esta prueba corresponde a: library(stats) ; shapiro. test(x).

## Jarque-Bera

La prueba de bondad de ajuste Jarque-Bera se basa en una estimación conjunta entre los coeficientes de asimetría y curtosis. Según (Thadewald y Büning, 2007) el estadístico JB está dado por la siguiente expresión:

$$
J B=\frac{n}{6}\left[S^{2}+\frac{(K-3)^{2}}{4}\right]
$$

donde la asimetría de la muestra utilizada está dada por $S^{2}=\frac{\widehat{\mu}_{3}}{\widehat{\mu}_{2}^{3 / 2}}$ que es un estimador de $\beta_{1}=\frac{\mu_{3}}{\mu_{2}^{3 / 2}}$ y la curtosis de la muestra es $K=\frac{\widehat{\mu}_{4}}{\widehat{\mu}_{2}^{2}}$ corresponde a un estimador de $\beta_{1}=\frac{\mu_{4}}{\mu_{2}^{2}}$; los valores de, donde $\mu_{2}, \mu_{3}$ y $\mu_{4}$ son el segundo, tercer y cuarto momento central estimados de la siguiente forma:

$$
\hat{\mu}_{j}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{j} \quad j=2,3,4
$$

Por otro lado, el estadístico $J B \sim \mathrm{X}_{(2)}^{2}$ (Thadewald y Büning, 2007, p. 91). Esto implica que la hipótesis $H_{0}$ contenida en la ecuación (2) se rechaza si el estadístico $J B$ es mayor o igual a un cuantil Chi-cuadrado con 2 grados de libertad:

$$
J B \geq \mathrm{X}_{(2,1-\alpha)}^{2}
$$

En R, este test se encuentra contenido en la siguiente función: library(tsoutliers) ; jarque. bera. test(x), en esta función si robust $=$ TRUE, entonces se hace uso del estadístico original establecido en (Jarque y Bera, 1980).

## Lilliefors (Kolmogorov-Smirnov)

Este test está basado en la prueba de Kolmogorov-Smirnov. ${ }^{5}$ Sin embargo, es una prueba no paramétrica que depende de conocer de antemano los valores de los parámetros que definen la distribución. Por este motivo, muchas veces obtener los valores reales de la media y la varianza es complejo. En casos así se pueden estimar desde una muestra que sea representativa y aleatoria (Mohd Razali y Yap, 2011, p. 23).

De esta forma, el estadístico de prueba $\left(K S_{L}=D\right)$ se define como la máxima diferencia absoluta entre la CDF (función de distribución acumulada) empírica y la CDF hipotética. ${ }^{6}$ En otras palabras, el estadístico $D$ tiene la siguiente expresión:

$$
D=\operatorname{má} x\left(D^{+}, D^{-}\right)
$$

Donde,

$$
D^{+}=\operatorname{má}_{i=1, \ldots, n}\left[\frac{i}{n}-p_{(i)}\right] \quad \text { y } \quad D^{-}=\operatorname{máx}_{i=1, \ldots, n}\left[p_{(i)}-\frac{(i-1)}{n}\right]
$$

En este caso $p_{(i)}=\Phi\left[\left(x_{(i)}-\frac{\bar{x}}{s}\right)\right]$. Siendo $\Phi$ la función de distribución acumulada de una distribución normal estándar en donde $\bar{x}$ y $s$ son la media y la varianza, respectivamente (Gross y Ligges, 2015). Además, $n$ representa el tamaño de la muestra.

La función en $R$ asociada a esta prueba de bondad de ajuste es la siguiente: library(nortest) ; lillie. test(x).

## Potencia de la prueba

Según (Chou-Chen, 2023) la potencia de la prueba se refiere a la probabilidad de rechazar la hipótesis nula cuando la hipótesis alternativa es cierta. Es decir, en un espacio paramétrico $\Omega$ segmentado en dos subconjuntos $\Omega_{0}$ y $\Omega_{1}$ de un parámetro $\theta$. El Error Tipo I $\alpha(\delta)$ se define tal que:
$\alpha(\delta)=P\left(\right.$ rechazar $H_{0}$ cuando es cierta $)=P\left(X \in R C_{\delta} \mid \theta \in \Omega_{0}\right)=\operatorname{Potencia}\left(\theta \mid \theta \in \Omega_{0}\right)$
Donde $R C_{\delta}$ es una zona de rechazo del contraste dado un $\theta \in \Omega_{0}$.

[^1]Y, por ende, también se puede definir el Error Tipo II que corresponde a no aceptar $H_{0}$ cuando en verdad es falsa. En otras palabras:

$$
\beta(\delta)=P\left(X \in R C_{\delta}^{c} \mid \theta \in \Omega_{0}\right)=1-\operatorname{Potencia}\left(\theta \mid \theta \in \Omega_{1}\right)
$$

La siguiente imagen muestra una representación visual de qué es la potencia de la prueba.

## Figura 3

Potencia de la prueba.
FIGURA A. 14
Función potencia de la prueba de hipótesis $\mu=50$ cuando $N=25$, $\sigma=10$ y $\alpha=0.05$.
Probabilidad de rechazar $H$

![](https://cdn.mathpix.com/cropped/2024_09_30_a62b0a14488a0b1bcc33g-07.jpg?height=381&width=630&top_left_y=715&top_left_x=1062)

Nota. Tomado de Inferencia estadística: pruebas de hipótesis, por (Gujarati y Porter, 2010, p. 835).

## SIMULACIÓN

Primeramente, en este estudio se utilizó el método de Montecarlo ${ }^{7}$ para evaluar la potencia de la prueba de Shapiro-Wilks, Jarque-Bera y Kolmogorov-Smirnov con corrección de Lilliefors. Además, para poder examinar el efecto del número de réplicas y número de tratamientos con distribución no normal en la potencia de pruebas de normalidad, se debió tener en cuenta los siguientes aspectos.

Por ende, se planteó un modelo experimental con dos factores $A$ (factor de diseño) y $B$ (factor de no diseño) cada uno con tres niveles y un efecto de interacción entre ellos dos. Por ende, la expresión que tomó este modelo fue la siguiente:

$$
\mu_{i j}=\mu+\alpha_{i}+\beta_{j}+(\alpha \beta)_{i j}
$$

Donde,

1. $\mu$ : media general.
2. $\alpha_{i}$ : efecto del factor de diseño, $i=1,2,3$.
3. $\beta_{j}$ : efecto del factor de no diseño, $j=1,2,3$.
4. $(\alpha \beta)_{i j}$ : efecto de interacción entre el factor de diseño y el factor de no diseño.

Este modelo se tomó como sugerencia del modelo experimental realizado por (Rodríguez Cruz et al., 2023).

Después de plantear el modelo, es de interés analizar el efecto del número de réplicas y la cantidad de tratamientos con distribución no normal en la potencia de las pruebas de normalidad.

[^2]Para ello, se generaron números aleatorios para cada tratamiento, donde la cantidad de números generados corresponde al número de réplicas especificado para ese tratamiento. Los números dentro de cada tratamiento se generaron siguiendo una distribución normal con media $\mu$ y varianza $4,{ }^{8}$ o una distribución exponencial con parámetro $\beta=2$, dependiendo del tratamiento. ${ }^{9}$

Además, se realizaron diferentes casos donde se modificó de forma aleatoria la cantidad de tratamientos que en primera instancia se distribuían normal por tratamientos que se distribuían de forma exponencial, hasta llegar a un total de 9 tratamientos con distribución no normal. Los datos utilizados en el análisis se obtienen de estos casos generados aleatoriamente. Cada tratamiento que provenía de una distribución normal tenía su propio valor de $\mu$. Estos valores fueron los siguientes: ${ }^{10}$

$$
\mu_{i j}=\left(\mu_{11}, \mu_{12}, \mu_{13}, \mu_{21}, \mu_{22}, \mu_{23}, \mu_{31}, \mu_{32}, \mu_{33}\right)=(4,6,2,3,4,3,6,5,4)
$$

Seguidamente, se prefirió un enfoque balanceado en el cual todos los tratamientos cuentan con la misma cantidad de réplicas. Esto implica que se asigna la misma cantidad de observaciones a cada tratamiento, independientemente de la distribución del tratamiento. Al mantener un diseño balanceado, se busca asegurar una comparación equitativa entre los tratamientos y minimizar cualquier sesgo potencial introducido por una distribución desigual de réplicas y solo enfocarse en el tópico de normalidad de los residuos. En consecuencia, para analizar la influencia de los tamaños de réplica, se tomaron en cuenta cuatro valores: ${ }^{11}$

$$
r=5,10,15,20
$$

Por lo tanto, se analizaron 36 escenarios por prueba de normalidad donde se calculó la potencia de la prueba con el mismo escenario para las tres (Shapiro-Wilks, Jarque-Bera y KSLilliefors); considere la siguiente tabla que muestra los casos.

[^3]Tabla 1
Cantidad de escenarios para las pruebas de bondad de ajuste $\left(S W, J B, K S_{L}\right)$.

| Distribuciones de tratamientos | Número de réplicas $(\boldsymbol{r})$ |  |  |  |
| :--- | :---: | :---: | :---: | :---: |
| 8 tratamientos con distribución $N(\mu, 4)$ y 1 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 7 tratamientos con distribución $N(\mu, 4)$ y 2 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 6 tratamientos con distribución $N(\mu, 4)$ y 3 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 5 tratamientos con distribución $N(\mu, 4)$ y 4 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 4 tratamientos con distribución $N(\mu, 4)$ y 5 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 3 tratamientos con distribución $N(\mu, 4)$ y 6 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 2 tratamientos con distribución $N(\mu, 4)$ y 7 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 1 tratamientos con distribución $N(\mu, 4)$ y 8 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |
| 0 tratamientos con distribución $N(\mu, 4)$ y 9 tratamiento $\operatorname{Exp}(2)$ | 5 | 10 | 15 | 20 |

Nota. La expresión $\operatorname{Exp}(2)$ hace referencia a una distribución Exponencial con parámetro $\beta=2$.
Teniendo los escenarios definidos, se creó una función con el objetivo de calcular los valores residuales del modelo ajustado, ecuación (6). En ella se generan los valores aleatorios de cada tratamiento dependiendo del caso en el cual se encontraba. Luego, se crearon los factores $A$ y $B$, cada uno con tres niveles. Posteriormente, se ajustó el modelo citado anteriormente, y se calcularon los valores residuales de él.

Dado esto, se estimó la proporción de veces que cada prueba de normalidad rechazó correctamente la hipótesis nula. ${ }^{12}$ Es decir, se evaluó si los residuos no seguían una distribución normal, considerando que no fueran normales. Además, para las tres pruebas de bondad de ajuste se tuvo en cuenta un nivel de significancia de $\alpha=0.05$. Es importante destacar que este valor de $\alpha$ implica que se rechazará $H_{0}$ si el valor $p$ es menor al nivel de significancia.

Seguidamente, se implementó una función que abarcó la lógica de simulación para calcular la potencia de las tres pruebas de normalidad en cada escenario posible. Por lo cual, se realizaron un total de diez mil iteraciones para cada escenario, y los resultados se almacenaron en vectores por separado según la prueba de bondad de ajuste cuando se rechazó la hipótesis nula.

En cada iteración, se generaron las observaciones correspondientes a cada tratamiento y se aplicaron las pruebas de normalidad. Asimismo, se calcularon los valores residuales con la función mencionada anteriormente y de esta manera se comprobó si alguna de las pruebas rechazaba la hipótesis nula de normalidad. Si ocurría esto, se registraba el resultado en el vector correspondiente a esa prueba con un 1, y en caso contrario, con un 0 . Además, esta función recopiló todos los cálculos en una base de datos para tener posterior control sobre las tablas y gráficos de los resultados.

[^4]De esta forma, este enfoque de simulación (realizado en la versión 4.3.1 de R) ${ }^{13}$ basado en múltiples iteraciones permitió evaluar la potencia de las pruebas de normalidad en diferentes escenarios y obtener una estimación fehaciente de su desempeño. Al almacenar los resultados en vectores separados, se pudo analizar y comparar la potencia de cada prueba de manera individual en función de los diferentes casos de distribución analizados.

## RESULTADOS

Una vez realizadas las diez mil iteraciones para cada uno de los escenarios propuestos en esta simulación, se encontraron aspectos que demostraron la influencia que tiene el número de réplicas y el número de tratamientos con distribución Exponencial con parámetro $\beta=2$ sobre la potencia de las pruebas de normalidad de los residuos descrita anteriormente.

A continuación, se procedió a elaborar la Tabla 2, que resume la potencia simulada en los distintos escenarios. Dicha tabla muestra las diferentes combinaciones de tratamientos y sus respectivos números de réplicas, considerando un nivel de significancia $\alpha=5 \%$. Por otro lado, se realizó la Figura 4, la cual está compuesta por una serie de sub-gráficos, donde cada uno representa una cantidad fija de réplicas. Dentro de cada sub-gráficos, se incrementa gradualmente la cantidad de tratamientos con distribución exponencial. En el eje y de cada sub-gráficos se muestra la potencia de la prueba. En resumen, la Figura 4 muestra de manera visual cómo cambia la potencia de la prueba al aumentar el número de tratamientos dado diferentes números de réplicas.

[^5]Tabla 2
Comparación de la potencia de la prueba para las diferentes pruebas de normalidad contra las combinaciones de distribuciones en los tratamientos.

| Distribución de tratamientos | Número de réplicas de <br> cada tratamiento $(r)$ | Potencia de la prueba |  |  |
| :---: | :---: | :---: | :---: | :---: |
|  |  | $\alpha=0.05$ |  |  |
|  |  | Shapiro-Wilks | Jarque-Bera | KS-Lilliefors |
| 8 tratamientos con distribución <br> $N(\mu, 4)$ y 1 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.0787 | 0.0699 | 0.0586 |
|  | 10 | 0.1230 | 0.1310 | 0.0708 |
|  | 15 | 0.1694 | 0.1804 | 0.0989 |
|  | 20 | 0.2085 | 0.2248 | 0.1026 |
| 7 tratamientos con distribución <br> $N(\mu, 4)$ y 2 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.1268 | 0.1202 | 0.0851 |
|  | 10 | 0.2516 | 0.2529 | 0.1519 |
|  | 15 | 0.3582 | 0.3607 | 0.2165 |
|  | 20 | 0.4566 | 0.4556 | 0.2774 |
| 6 tratamientos con distribución <br> $N(\mu, 4)$ y 3 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.1929 | 0.1851 | 0.1203 |
|  | 10 | 0.4066 | 0.3849 | 0.2696 |
|  | 15 | 0.5858 | 0.5544 | 0.4170 |
|  | 20 | 0.7289 | 0.6824 | 0.5566 |
| 5 tratamientos con distribución <br> $N(\mu, 4)$ y 4 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.2676 | 0.2441 | 0.1696 |
|  | 10 | 0.5941 | 0.5430 | 0.4375 |
|  | 15 | 0.7926 | 0.7349 | 0.6429 |
|  | 20 | 0.9060 | 0.8443 | 0.7963 |
| 4 tratamientos con distribución <br> $N(\mu, 4)$ y 5 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.3663 | 0.3221 | 0.2469 |
|  | 10 | 0.7588 | 0.6818 | 0.6116 |
|  | 15 | 0.9275 | 0.8689 | 0.8288 |
|  | 20 | 0.9827 | 0.9517 | 0.9402 |
| 3 tratamientos con distribución <br> $N(\mu, 4)$ y 6 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.4711 | 0.4060 | 0.3318 |
|  | 10 | 0.8821 | 0.8143 | 0.7628 |
|  | 15 | 0.9841 | 0.9509 | 0.9364 |
|  | 20 | 0.9986 | 0.9877 | 0.9891 |
| 2 tratamientos con distribución <br> $N(\mu, 4)$ y 7 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.5810 | 0.4959 | 0.4190 |
|  | 10 | 0.9583 | 0.9058 | 0.8807 |
|  | 15 | 0.9981 | 0.9896 | 0.9832 |
|  | 20 | 0.9998 | 0.9983 | 0.9980 |
| 1 tratamientos con distribución <br> $N(\mu, 4)$ y 8 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.6935 | 0.5936 | 0.5270 |
|  | 10 | 0.9880 | 0.9652 | 0.9410 |
|  | 15 | 1.0000 | 0.9982 | 0.9972 |
|  | 20 | 1.0000 | 0.9999 | 0.9998 |
| 0 tratamientos con distribución <br> $N(\mu, 4)$ y 9 tratamiento $\operatorname{Exp}(2)$ | 5 | 0.7962 | 0.6894 | 0.6236 |
|  | 10 | 0.9987 | 0.9941 | 0.9816 |
|  | 15 | 1.0000 | 0.9999 | 0.9994 |
|  | 20 | 1.0000 | 1.0000 | 1.0000 |

Primeramente, se detectó que las tres pruebas analizadas en un escenario de 5 réplicas por tratamiento presentaron valores de la potencia relativamente bajos, en especial la prueba no paramétrica de Lilliefors (Kolmogorov-Smirnov), inclusive cuando los nueve tratamientos provenían de una distribución asimétrica positiva como lo fue la distribución exponencial. Este aspecto, es
posible ligarlo en saber que en tamaños de muestras pequeños todas las pruebas tienen una sensibilidad a no encontrar esas diferencias cuando en verdad sí las hay (Noughabi, 2018). No obstante, la prueba paramétrica Shapiro-Wilks fue la que logró llegar a un umbral cercano de $80 \%$ de la potencia de la prueba, exactamente de 0.7962. ${ }^{14}$

Por otro lado, hubo similitudes entre las pruebas paramétricas de Jarque-Bera y ShapiroWilks en casos donde se contaba con una o dos distribuciones exponenciales, y las restantes siete distribuciones eran normales, esto para cada número de réplicas empleado. Este patrón se observó en los dos primeros puntos (azules y verdes) de las cuatro rejillas (total de réplicas por tratamiento) que se muestran en la Figura 4, para cada número de réplicas utilizado.

Figura 4
Resultados de la potencia de la prueba por tipo de prueba de bondad de ajuste.

![](https://cdn.mathpix.com/cropped/2024_09_30_a62b0a14488a0b1bcc33g-12.jpg?height=1088&width=1546&top_left_y=901&top_left_x=281)

Igualmente, un hecho importante de mencionar es como la prueba no paramétrica de Lilliefors (Kolmogorov-Smirnov) fue, en todos los escenarios posibles, la prueba de bondad de ajuste que obtuvo las potencias del supuesto de normalidad de los residuos más bajas en comparación de sus homólogas paramétricas Shapiro-Wilks y Jarque-Bera. Parte de los resultados tan distantes obtenidos con Lilliefors (Kolmogorov-Smirnov) se basan, como menciona (Pedrosa et al., 2014), a su: «tendencia excesivamente conservadora» (p.250). Sin embargo, esta corrección de la prueba de Kolmogorov-Smirnov ha demostrado ser óptima en comparación con la prueba original propuesta

[^6]por Andrey Nikolaevich Kolmogorov en 1933. ${ }^{15}$ En otras palabras, la prueba de Lilliefors (Kolmogorov-Smirnov) tiene la capacidad de refutar la hipótesis nula $H_{0}$ en un porcentaje específico de situaciones, dependiendo del tamaño de la muestra.

En cuanto a las diferencias que mostró la prueba de Shapiro-Wilks en comparación con de Jarque-Bera y Lilliefors (Kolmogorov-Smirnov) se ven explícitamente cuando se tienen más de tres distribuciones asimétricas positivas y seis normales. En este caso, en la Figura 4 (y en la Tabla 2) la línea verde (Shapiro-Wilks) Ilega a aventajar a la azul (Jarque-Bera) y a la roja (Kolmogorov-Smirnov con corrección de Lilliefors) en el aspecto de poseer valores de potencia del cumplimiento del supuesto de normalidad de residuos más altos. Asimismo, se ve una diferencia más pronunciada si solo se toma en cuenta la línea verde y roja. La prueba de Jarque-Bera se llega a alejar un poco de los resultados de la prueba de Shapiro-Wilks, pero no tan marcada como la prueba de Lilliefors (Kolmogorov-Smirnov).

Finalmente, esta simulación logró evidenciar que al estar en escenarios con números de réplicas grandes (por ejemplo, con 15 y 20) y que poseen al menos un total de 6 distribuciones exponenciales por tratamiento, las potencias calculadas fueron muy similares entre ellas. Este hecho, (Farrell y Rogers-Stewart, 2006) lo trabaja en su estudio de simulación y argumenta que, al incrementar paulatinamente el tamaño de muestra, los resultados de las potencias de diversas pruebas de bondad de ajuste llegan a niveles similares. En este caso, como se observa en la Figura 4 en la rejilla de la esquina inferior derecha, en su mayor parte todas las pruebas analizadas a partir de 6 distribuciones asimétricas por tratamiento llegan a obtener una potencia de la prueba mayor a 0.90. Asimismo, en la Tabla 2 se pueden observar todos los resultados obtenidos de esta simulación.

## CONCLUSIONES

Mediante el análisis de los resultados obtenidos en esta simulación se entrelazó con otros estudios previos que trabajaron el análisis de la potencia del cumplimento del supuesto de normalidad desde diversas metodologías y enfoques que dan ruta a seguir mejorando y analizando estudios como este.

Primero, la prueba de Shapiro-Wilks (paramétrica) con el estadístico $W$ logró obtener resultados semejantes a los que (Mendes y Pala, 2003; Mohd Razali y Yap, 2011) mostraron en su estudio de simulación; independientemente del número de réplicas y de la cantidad específica de tratamientos con distribución exponencial, se observó que esta prueba era consistentemente la más efectiva en términos de potencia en comparación con las demás pruebas utilizadas. No obstante, en trabajos como los de (Nosakhare y Bright, 2017) donde se trabajó con distintos tipos de distribuciones (simétricas y asimétricas positivas) se sugiere reemplazar la prueba de Shapiro-Wilks por su homóloga con corrección Shapiro-Francia, tanto para muestras pequeñas como grandes.

Como se evidenció en la sección anterior, esta simulación también siguió el mismo hilo de resultados que autores como (Farrell y Rogers-Stewart, 2006) argumentan sobre la influencia que llega a tener el tamaño de la muestra (número de réplicas por tratamiento) sobre el cálculo de la

[^7]potencia, ya que, a mayor tamaño de muestra, mayor potencia, independientemente de la cantidad de distribuciones exponenciales para este caso.

Igualmente, según (Mohd Razali y Yap, 2011; Thadewald y Büning, 2007) la prueba no paramétrica de Kolmogorov-Smirnov con corrección de Lilliefors es la que tiene menor rendimiento en comparación con las otras dos pruebas. Esto se debe a que se le dificulta rechazar que los residuales de un modelo se distribuyen normal cuando en realidad esto pasa, en parte se debe a su metodología más robusta y conservadora que sus homólogas paramétricas Shapiro-Wilks y JarqueBera.

En resumen, esta simulación se convierte en un punto de referencia para analizar otras distribuciones asimétricas positivas, como la distribución Gamma, Log-Normal, Pareto, entre otras. ${ }^{16}$ Esto se debe a que, dependiendo de las características de cada una de estas distribuciones, los resultados obtenidos mediante el enfoque propuesto en este trabajo podrían variar. De esta manera, se podría obtener un panorama más completo sobre el efecto que tienen el número de réplicas y el número de tratamientos con distribuciones no normales en los resultados de la potencia de pruebas del cumplimiento del supuesto de normalidad de los residuos. Esto es especialmente relevante en presencia de distintos estadísticos que analizan la hipótesis mencionada en la expresión (2).

Además, se alienta a futuros investigadores a combinar el objetivo de este estudio de simulación con otros aspectos que puedan demostrar una influencia negativa o positiva en el cumplimiento del supuesto de normalidad. Es decir, se les anima a explorar la incorporación de valores extremos, la presencia de heterocedasticidad u otros inconvenientes que suelen estar presentes al ajustar un modelo experimental e incluso trabajar con modelos experimentales más complejos.

[^8]
## ANEXOS

## Anexo l: Código de la simulación

En la siguiente tabla se proporciona el código utilizado para la realización de la simulación propuesta en la plataforma de R en su versión 4.3.1. Además, se adjuntan una serie de comentarios que hacen posible seguir el hilo conductor del enfoque de esta simulación.

## Tabla 3

Código de la simulación comentado.

| Efecto del número de réplicas y número de tratamientos con distribución no normal en la <br> potencia de pruebas de normalidad. |  |
| :---: | :---: |
| Primera parte |  |
| Código | Explicación |
| trat.distribucion $=$ function( $\mathrm{n}, \mathrm{mu}, \mathrm{v}=4$, <br> iteracion) $\{$ | Creamos una función la cual utiliza de parámetros <br> un vector de $n$, un vector de mu, las cuales van a <br> ser los mu de cada tratamiento para las <br> distribuciones normales, una variancia fijada en 4 <br> que es la variancia de todas las distribuciones de <br> los tratamientos y la iteración es solo utilizada <br> para la siguiente función de la simulación, dentro <br> de esta función esa iteración lo que va a hacer es <br> calcular la cantidad de $n$-(r*iteracion) que se <br> ocupa generar con distribuciones normales y <br> r*iteracion la cantidad de valores de la <br> distribución exponencial. Se va a estar iterando la <br> cantidad de distribuciones exponenciales que <br> tienen que haber es decir que ese parámetro <br> denominado interacción va a subir hasta llegar a 9 <br> puesto que hay un total de 9 tratamientos. Esta <br> función nos genera los escenarios y nos va a dar <br> los residuales para cada escenario para poder <br> calcular las potencias de la prueba de normalidad <br> para cada caso. |
| k = 9 \# La simulación se basa en tener 10 <br> tratamientos siempre <br> $r=n / k$ \# Cantidad de réplicas por <br> tratamiento, la simulación es con un diseño <br> experimental balanceado <br> if $((n-r *$ iteracion $)==0)\{$ | En caso de que ya vayamos por la última iteración <br> de las distribuciones, es decir que ya se <br> removieron todas las distribuciones normales y <br> ahora se ocupan generar todos los valores de cada <br> factor con distribución Exponencial(2) para poder <br> hacer la potencia con todos los tratamientos <br> generados con distribución exponencial. |
| x1 = factor(rep(1:k/2, each = r)) | Se crea el factor de A con 3 niveles con $r$ <br> repeticiones por nivel. |


| x2 = factor(rep(1:k/2, each $=r))$ | Se crea el factor B con 3 niveles con r repeticiones <br> por nivel. |
| :---: | :---: |
| $y=\operatorname{rexp}(n=n$, rate $=\operatorname{rep}(1 / 2$, each $=r))$ <br> $\}$ | Se genera la variable respuesta para cada factor <br> con una distribución exponencial de tamaño $n$, es <br> decir el total de observaciones, por cada <br> tratamiento se hizo dentro de la función rexp con <br> un rate $=$ rep( $1 / 2$, each=r) para que a cada factor <br> se le asigne correctamente la varianza de 4 |
| if ((n-r*iteracion)! $=0)\{$ | Este caso se cumple siempre cuando no se vaya <br> por la última interacción de las distribuciones <br> exponenciales es decir que va a generar una <br> cantidad de tratamientos k-interacciones de <br> distribución normal con los parámetros que <br> queden del vector de mu. |
| y_norm = rnorm(n-(r*iteracion), <br> rep(mu,each=r), sqrt(v)) | Se generan n-(r**teracion) valores de distribución <br> normal en la cual se distribuye a cada uno de los <br> tratamientos dependiendo del mu asignado en el <br> vector del parámetro de la función. |
| x 1 = factor(rep(1:k/2, each $=\mathrm{r})$ ) | Se crea el factor de A con 3 niveles con $r$ <br> repeticiones por nivel. |
| $x 2$ = factor(rep $(1: k / 2$, each $=r))$ | Se crea el factor $B$ con 3 niveles con $r$ repeticiones <br> por nivel. |
| y = c(y_norm,rexp(n = r*iteracion, rate = <br> rep $(1 / 2$, each $=r)))$ <br> $\}$ | Se genera un vector combinado de la variable <br> y_norm con valores de una distribución <br> exponencial de rexp tamaño r*iteracion, para que <br> de esta manera tener el $n$ que sale de parámetro <br> en función. |
| $\bmod =\operatorname{aov}\left(y^{\sim} x 1+x 2+x 1: x 2\right)$ | Se genera un modelo para poder obtener los <br> residuales del modelo y poder evaluar la <br> normalidad. |
| return(mod\$\$res) <br> \} | Devolvemos los residuales del modelo. |
| Segunda parte |  |
| simulacion.completa = function( n.ast = <br> $c\left(5^{*} 9,10^{*} 9,15^{*} 9,20^{*} 9\right)$, mu_fijo $=$ <br> $c(4,6,2,3,4,3,6,5,4))\{$ | Esta función utiliza los parámetros, n.ast en donde <br> va a ser un vector de los valores de $n$ los cuales van <br> a ser los casos de análisis de la cantidad de <br> repeticiones por tratamiento, después tenemos el <br> mu_fijo el cual es un vector de mu el cual son los <br> promedios que se utilizaran para generar las <br> distribuciones normales. Esta función calcula la <br> proporción de veces que se rechaza la hipótesis <br> nula para cada prueba de normalidad y cada <br> escenario y las guarda en una lista para poder <br> después devolver una base de datos la cual <br> contenga al final todos los valores necesarios para <br> saber la potencia de cada prueba para cada valor |


|  | de n y cada combinación de tratamiento de <br> distribuciones normales con exponenciales. |
| :---: | :---: |
| aleatorio = sample(mu_fijo, length(mu_fijo)) | Generamos un sample el cual siempre se va a <br> mantener, y este sirve para poder eliminar <br> aleatoriamente un mu del vector mu_fijo al azar. <br> Además, de poder insertar de esta manera una <br> cantidad de 5 valores de distribución exponencial <br> con parámetro lambda $=1 / 2$. |
| data $=\operatorname{list}($ ) | Lista en la cual vamos a guardar las potencias de <br> las pruebas de normalidad, nombres de las <br> pruebas, tamaño de n e la cantidad de <br> tratamientos con distribuciones exponenciales de <br> $1 / 2$ a la hora de realizar la simulación. |
| $\mathrm{m}=1$ | Este m nos ayudará a ir insertando en la lista. |
| pruebas = c("Shapiro-Wilks","Jarque- <br> Bera","KS-Lilliefors") | Nombres de las pruebas para mayor facilidad de <br> insertar el nombre en la lista donde guardamos las <br> potencias y la cantidad de $n$. |
| for (k in 1:length(n.ast))\{ | Ciclo for el cual va a permitir correr a través de <br> todas las $n$ para poder iterar a través de todos los <br> casos de los valores de la $n$ nombrados <br> anteriormente en el vector de n.ast, es decir que <br> se itera a través de todos los casos de las n para <br> poder ver las potencias para cada caso de $n$. |
| mu = mu_fijo | Definimos $m u=m u \_$fijo puesto que se va a estar <br> actualizando este parámetro para de esta manera <br> ir quitándole al azar el mu de un tratamiento. |
| for (j in 1:length(mu_fijo))\{ | Este ciclo for sirve para poder iterar toda la lista de <br> mu_fijo es decir del vector de mues, este es el <br> valor que metemos en la iteración de la función <br> anterior puesto que con esto vamos a saber <br> cuántas distribuciones exponenciales hay. Cada <br> vez que avance el $j$ significa que hay una <br> distribución exponencial más. |
| almacen.shap $=\operatorname{rep}(\mathrm{NA}, 10000)$ | Almacén en la cual vamos a guardar los valores de <br> la potencia de la prueba de Shapiro-Wilks. |
| almacen.jb = rep(NA,10000) | Almacén en la cual vamos a guardar los valores de <br> la potencia de la prueba de Jarque-Bera. |
| almacen.ksl $=\operatorname{rep}(\mathrm{NA}, 10000)$ | Almacén en la cual vamos a guardar los valores de <br> la potencia de la prueba de KS-Lilliefors. |
| for (i in 1:10000)\{ | Simulación de 10.000 iteraciones para saber <br> cuántas veces se rechaza la hipótesis nula. |
| $residuales=$ <br> $trat.distribucion(n.ast[k],mu=mu,iteracion=$ <br> $j)$ | Generamos los residuales utilizando la función <br> hecha anteriormente. |
| almacen.shap $[i]=$ <br> $1^{*}($ shapiro.test $($ residuales)\$p.value $<0.05)$ | Almacenamos en nuestros almacenes nombrados <br> en este caso almacen.shap anteriormente, cuando <br> se rechaza la hipótesis nula, cada vez que se |


|  | rechace se le asigna un 1 y cuando no logra <br> rechazar un 0 . |
| :---: | :---: |
| $almacen.jb[i]=$ <br> $1*(jarque.bera.test(residuales)$p.value<$ <br> $0.05)$ | Almacenamos en nuestros almacenes nombrados <br> anteriormente, cuando se rechaza la hipótesis <br> nula. |
| fa4228164-1be2-4938-b16c-6c17f179104f}$almacen.ksl[i]=$ <br> $1*(lillie.test(residuales)$p.value<0.05)$ <br> $\begin{array} { l } { almacen.ksl[i]= } \\ { 1*(lillie.test(residuales)$p.value < 0.05) } \\ { }${f6b04f5f6-39d2-4ea6-b37f-8c433ad74419 |  |$} &{$| \(Almacenamos en nuestros almacenes nombrados \) |
| :--- |
| \(anteriormente en este caso almacen.ksl, cuando \) |
| \(se rechaza la hipótesis nula. \) |\(} <br>

{\hline\)\begin{tabular}{l}
\(data[[m]] =\) <br>
\(c(pruebas[1],mean(almacen.shap),n.ast[k],j)\)

$} &{$

\(Ahora cuando salimos de la simulación de 10.000\) <br>
\(veces guardamos la potencia de la prueba en la\) <br>
\(lista, nombrada al principio de la función, dentro\) <br>
\(de esta se guarda; el nombre de la prueba en este\) <br>
\(caso es Shapiro-Wilks; el promedio del almacén de\) <br>
\(Shapiro, es decir cuantas veces pudo rechazar HO\) <br>
\(cuando H1 es cierta; el n es decir la cantidad de\) <br>
\(réplicas totales, en la cual se hizo el análisis de la\) <br>
\(potencia; y el j que es la cantidad de tratamientos\) <br>
\(que hay con distribución exponencial en la cual se\) <br>
\(utilizó para calcular la potencia de la prueba.\)
\end{tabular}\(} <br>

{\hline m=m+1} \&{\)| \(Le sumamos un  1  al índice de m para poder \) |
| :--- |
| \(insertar el siguiente valor en la lista. \) |\(} <br>

{\hline\)\begin{tabular}{l}

| \(data [[m]]=\) |
| :--- |
| $c(\text { pruebas[2],mean(almacen.jb),n.ast[k],j) }$ |


$} &{$

\(Guardamos la potencia de la prueba en la lista,\) <br>
\(nombrada al principio de la función, dentro de\) <br>
\(esta se guarda; el nombre de la prueba en este\) <br>
\(caso es Jarque-Bera; el promedio del almacén de\) <br>
\(JB, es decir cuantas veces pudo rechazar HO\) <br>
\(cuando H1 es cierta; el n es decir la cantidad de\) <br>
\(réplicas totales, en la cual se hizo el análisis de la\) <br>
\(potencia; y el j que es la cantidad de tratamientos\) <br>
\(que hay con distribución exponencial en la cual se\) <br>
\(utilizó para calcular la potencia de la prueba.\)
\end{tabular}\(} <br>

{\hline m=m+1} \&{\)| \(Le sumamos un  1  al índice de m para poder \) |
| :--- |
| \(insertar el siguiente valor en la lista. \) |\(} <br>

{\hline\)\begin{tabular}{l}
$data[[m]]=$ <br>
$c(pruebas[3],mean(almacen.ksl),n.ast[k],j)$

$} &{$

\(Guardamos la potencia de la prueba en la lista,\) <br>
\(nombrada al principio de la función, dentro de\) <br>
\(esta se guarda; el nombre de la prueba en este\) <br>
\(caso es K-S Lilliefors; el promedio del almacén de\) <br>
\(ksl, es decir cuantas veces pudo rechazar HO\) <br>
\(cuando H1 es cierta; el n es decir la cantidad de\) <br>
\(réplicas totales, en la cual se hizo el análisis de la\) <br>
\(potencia; y el j que es la cantidad de tratamientos\) <br>
\(que hay con distribución exponencial en la cual se\) <br>
\(utilizó para calcular la potencia de la prueba.\)
\end{tabular}\(} <br>

{\hline m=m+1} \&{\)| \(Le sumamos un  1  al índice de m para poder \) |
| :--- |
| \(insertar el siguiente valor en la lista. \) |\(} <br>

\)\hline$\end{array}$

| ${mu}=\textrm{mu[-aleatorio[j]]}$ <br> $\begin{array} { l } { mu}=\textrm{mu[-aleatorio[j]] } \\ { }${fdb6aad13-3f4f-41d3-914e-c8658e0243ab} |
| :---: | :---: |
| ${ } }$ |$} &{$| \(Aquí es donde usamos la información que nos dio \) |
| :--- |
| \(el sample definido al principio de la función para \) |
| \(que de esta manera se remueva al azar un valor \) |
| \(del vector de mues de distribución normal e \) |
| \(insertar en lugar de ese tratamiento con \) |
| \(distribución normal una distribución exponencial, \) |
| \(ya que el  j  va a avanzar, hasta llegar a tener todos \) |
| \(los tratamientos generados con distribuciones \) |
| \(exponenciales. Y cuando esto sucede se prosigue \) |
| \(al primer for loop hecho es decir se repite todo, \) |
| \(pero con otro tamaño de  n . \) |\(} <br>

{\hline \multicolumn{2}{|l|}{Tercera parte}Tercera parte} <br>

{\hline data = as.data.frame(do.call("rbind",data))} \&{\)| \(Reestructuramos la lista llamada data, es decir \) |
| :--- |
| \(toda la información conseguida de todos los \) |
| \(escenarios posibles con las tres pruebas, en un \) |
| \(dataframe para tener mejor visualización de los \) |
| \(datos. \) |\(} <br>

{\hline\)\begin{tabular}{l}
\(colnames(data) = c("Normalidad",\) <br>
\("Potencia", "N", "Distribuciones")\)

$} &{$

\(Definimos los nombres de las columnas del\) <br>
\(dataframe de data.\)
\end{tabular}\(} <br>

{\hline\)\begin{tabular}{l}
\(return(data)\) <br>
\(\}\)

$} &{$

\(Por último, devolvemos el data frame creado\) <br>
\(llamado data para poder tener visualización de los\) <br>
\(resultados y poder hacer análisis gráfico.\)
\end{tabular}\(} <br>

{\hline\)| $\text { data }=\text { simulacion.completa( })$ |
| :--- |
| \(\# Visualizar la base: \) |
| \(data \) |\(} \&{Obtenemos los resultados y los visualizamos.} <br>

\)\hline$\end{array}$

Nota. Este código consta de tres partes generales. La primera de ellas corresponde al cálculo de los valores residuales con las pautas mencionadas en la METODOLOGÍA, la segunda sección está asociada al cálculo de la potencia de la prueba para cada una de las tres pruebas de bondad de ajuste que se utilizaron y la última parte corresponde a la reestructuración de los datos para la generación de una base de datos que ayude a mostrar los datos de forma óptima para el análisis y la visualización de los resultados, como las tablas o los gráficos presentes en este documento.

## BIBLIOGRAFÍA

Chou-Chen, S. W. (2023, May). Clase 15: Contrastes de hipótesis. Teoría Estadística. https://shuwei325.github.io/XS3310-I23/XS3310-I23_15.html\#3

Coin, D. (2008). Testing normality in the presence of outliers. Statistical Methods and Applications, 17, 3-12. https://doi.org/https://doi.org/10.1007/s10260-007-0046-8

Dufour, J., Farhat, A., Gardiol, L., y Khalaf, L. (1998). Simulation-based finite sample normality tests in linear regressions. The Econometrics Journal, 1(1), C154-C173. https://doi.org/10.1111/1368-423X. 11009

Farrell, P. J., y Rogers-Stewart, K. (2006). Comprehensive study of tests for normality and symmetry: extending the Spiegelhalter test. Journal of Statistical Computation and Simulation, 76(9), 803816. https://doi.org/10.1080/10629360500109023

Gross, J., y Ligges, U. (2015). lillie.test: Lilliefors (Kolmogorov-Smirnov) test for normality. Nortest: Tests for Normality. https://www.rdocumentation.org/packages/nortest/versions/1.04/topics/lillie.test

Gujarati, D. N., y Porter, D. C. (2010). Econometría (5th ed.). McGraw-Hill/Irwin, Inc.
Jarque, C. M., y Bera, A. K. (1980). Efficient tests for normality, homoscedasticity and serial independence of regression residuals. Economics Letters, 6(3), 255-259. https://doi.org/https://doi.org/10.1016/0165-1765(80)90024-5

Mak, T. K. (2000). Heteroscedastic regression models with non-normally distributed errors. Journal of Statistical Computation and Simulation, 67(1), 21-36. https://doi.org/10.1080/00949650008812034

Mendes, M., y Pala, A. (2003). Type I Error Rate and Power of Three Normality Tests. Information Technology Journal, 2(2), 135-139. https://doi.org/10.3923/itj.2003.135.139

Mohd Razali, N., y Yap, B. (2011). Power Comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling Tests. J. Stat. Model. Analytics, 2. https://www.researchgate.net/publication/267205556_Power_Comparisons_of_ShapiroWilk_Kolmogorov-Smirnov_Lilliefors_and_Anderson-Darling_Tests

Nosakhare, U. H., y Bright, A. F. (2017). Evaluation of Techniques for Univariate Normality Test Using Monte Carlo Simulation. American Journal of Theoretical and Applied Statistics, 6(5-1), 51-61. https://www.sciencepublishinggroup.com/journal/paperinfo?journalid=146ydoi=10.11648/j. ajtas.s. 2017060501.18

Noughabi, H. A. (2018). A Comprehensive Study on Power of Tests for Normality. Journal of Statistical Theory and Applications, 17(4), 647-660. https://doi.org/10.2991/jsta.2018.17.4.7

Pedrosa, I., Juarros-Basterretxea, J., Robles-Fernández, A., Basteiro, J., y García-Cueto, E. (2014). Pruebas de bondad de ajuste en distribuciones simétricas, ¿qué estadístico utilizar? Universitas Psychologica, 14(1), 245-254. https://doi.org/10.11144/Javeriana.upsy14-1.pbad

Rodríguez Cruz, I. D., Camacho Pochet, M., Cedeño Guzmán, A., y Villalobos Martínez, M. S. (2023). Efecto del grado de acidez del suelo $(\mathrm{pH})$ y la temperatura sobre el crecimiento del largo promedio de las ra'ıces de semillas de lechuga Great Lakes 118.

Shapiro, S. S., y Wilk, M. B. (1965). An Analysis of Variance Test for Normality (Complete Samples). Biometrika, 52(3/4), 591-611. https://doi.org/10.2307/2333709

Thadewald, T., y Büning, H. (2007). Jarque-Bera Test and its Competitors for Testing Normality - A Power Comparison. Journal of Applied Statistics, 34(1), 87-105. https://doi.org/10.1080/02664760600994539

Ventura-León, J., Peña-Calero, B. N., y Burga-León, A. (2022). The effect of normality and outliers on bivariate correlation coefficients in psychology: A Monte Carlo simulation. The Journal of General Psychology, 1-18. https://doi.org/10.1080/00221309.2022.2094310


[^0]:    ${ }^{1}$ Estudiante de Estadística de la Universidad de Costa Rica.
    ${ }^{2}$ Estudiante de Estadística de la Universidad de Costa Rica
    ${ }^{3}$ Estudiante de Estadística y Sociología de la Universidad de Costa Rica.
    ${ }^{4}$ Estudiante de Estadística de la Universidad de Costa Rica.

[^1]:    ${ }^{5}$ Véase el desarrollo de este estadístico en (Thadewald y Büning, 2007).
    ${ }^{6}$ CDF por sus siglas en inglés Cumulative distribution function.

[^2]:    ${ }^{7}$ También conocido como simulaciones de Montecarlo (Nosakhare y Bright, 2017).

[^3]:    ${ }^{8}$ Se analizó la simulación con una varianza fija.
    ${ }^{9}$ En este caso se utilizó un $\beta=2$ puesto que se quiso tener presencia de homocedasticidad en los datos.
    ${ }^{10}$ La elección de los promedios de cada tratamiento fue un aproximado de los obtenidos en el experimento de Rodríguez Cruz et al. (2023).
    ${ }^{11}$ Estos valores generalmente son usados en los estudios de investigación como los de (Mohd Razali y Yap, 2011; Thadewald y Büning, 2007). Además, el valor asignado a cada $n$ en función de $r$ es igual a $n=r \times 9$.

[^4]:    ${ }^{12}$ Ver el contraste contenido en la expresión (2).

[^5]:    ${ }^{13}$ Se usaron ciertas librerías como: tidyverse (2.0.0), stats (4.4.0), tsoutliers (0.6-8), nortest (1.0-4), entre otras.

[^6]:    ${ }^{14}$ Como se observa en la Tabla 2 en nueve tratamientos con distribución $\operatorname{Exp}(2)$ con cinco réplicas.

[^7]:    ${ }^{15}$ El texto Goodness-of-Fit Techniques de Ralph B. D’Agostino (1986) recopila parte de la metodología usada por Andrey N. Kolmogorov en la primera versión del estadístico $D, \sin$ ninguna corrección aplicada.

[^8]:    ${ }^{16}$ Véase estudios de simulación como el de (Nosakhare y Bright, 2017).

